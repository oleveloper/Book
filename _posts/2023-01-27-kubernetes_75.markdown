---
layout: post
title: "Kubernetes_75 Design a Kubernetes Cluster"
date: 2023-01-27
last_modified_at: 2023-01-27
categories: [Kubernetes]
tags: [Kubernetes]
---

# Design a Kubernetes Cluster

클러스터 설계를 시작하기 전에 다음과 같은 질문을 해야 한다.   
이 클러스터의 목적은 무엇일까? 학습, 개발 또는 테스트 목적일까, 아니면 production 애플리케이션을 호스팅하기 위한 것일까? 회사의 클라우드 채택 현황은 어떤가? 클라우드 공급자가 관리하는 플랫폼을 선호하는가, 아니면 자체 호스팅하는 플랫폼을 선호하는가? 이 클러스터에서 실행할 워크로드의 종류는 무엇인가? 클러스터에서 호스팅할 애플리케이션 수는? 적은가? 아니면 많은가? 애플리케이션이 클러스터, 웹 애플리케이션 또는 빅 데이터 또는 분석에 호스팅되는가? 애플리케이션의 종류에 따라 리소스 요구 사항이 달라질 수 있다. 애플리케이션이 예상하는 네트워크 트래픽 유형, 지속적인 트래픽량, burst는 무엇일까? 자, 이것들 중 몇 가지를 낱낱이 파헤쳐 보자.   

학습 목적으로 클러스터를 구축하려는 경우 로컬 VM 또는 GCP, AWS와 같은 클라우드 프로바이더에 kubeadm을 사용하여 구축된 단일 노드 클러스터 또는 minikube 기반 솔루션을 사용해야 한다.   
개발 및 테스트 목적으로 클러스터를 구축하려면 단일 마스터 노드와 다중 작업자 노드가 있는 다중 노드 클러스터가 도움이 된다.   
kubeadm은 적절한 도구이며, managed 클라우드 환경의 경우 GCP의 Google 컨테이너 엔진 또는 AWS 또는 Azure의 AKS 솔루션을 사용하여 신속하게 클러스터를 프로비저닝하도록 한다.   

프로덕션 레벨 클러스터에 대해 알아보자.   
프로덕션급 애플리케이션을 호스팅하는 경우 여러 마스터 노드가 있는 고가용성 다중 노드 클러스터가 권장된다.   
추후 여러 마스터 노드를 사용한 고가용성 설정에 대해 자세히 알아보자.   
다시 말하지만, 이것은 kubeadm이나 GCP, AWS 또는 기타 지원 플랫폼에서 Kops를 사용하여 설정할 수 있다.   
클러스터에는 최대 5,000개의 노드, 클러스터에는 총 150,000개의 pod, 총 300,000개의 컨테이너, 노드당 최대 100개의 pod를 가질 수 있다.   

클러스터 크기에 따라 노드의 리소스 요구 사항이 달라진다.   
GCP 및 AWS와 같은 클라우드 서비스 공급자는 클러스터의 노드 수에 따라 사용자에게 적합한 크기의 노드를 자동으로 선택한다.   
다음 표에서는 특정 노드 수에 대한 인스턴스의 크기와 리소스 사양을 보여 준다.   
<img width="1078" alt="스크린샷 2023-01-27 오후 10 39 56" src="https://user-images.githubusercontent.com/83587720/215100463-6fba7e1d-d1c2-4803-a631-b62aa72fea13.png">   
온프레미스 노드를 배포하는 경우 이 숫자를 space으로 시작할 수 있다.   
클라우드든 온프레미스든 이러한 모든 구현 옵션을 모든 환경에서 사용할 수 있다는 점에 대해 이미 앞서 언급했었다.
온프레미스의 경우 kubeadm은 매우 유용한 도구이다.   

Google 컨테이너 엔진은 Kubernetes 클러스터를 GCP에 매우 쉽게 프로비저닝한다.   
클러스터를 매우 쉽게 유지 관리할 수 있는 원클릭 클러스터 업그레이드 기능이 제공된다.   
Kops는 AWS에 Kubernetes 클러스터를 배포하는 좋은 도구이다.   
그리고 AKS(Azure Kubernetes Serivce)는 Azure에서 호스팅되는 Kubernetes 환경을 관리하는 데 도움이 된다.   

구성된 워크로드에 따라 노드와 구성 해제 disconfiguration 가 달라진다.   
고성능 워크로드(high performance workloads)의 경우 SSD 기반 스토리지를 사용한다.   
다중 동시 액세스(multiple concurrent access)의 경우 네트워크 기반 스토리지를 고려한다.   
여러 Pod에서 볼륨에 대한 공유 액세스를 하는 경우, 스토리지 섹션에서 설명한 Persistence storage volume을 고려해야 한다.   
서로 다른 클래스의 스토리지를 정의하고 올바른 클래스를 올바른 애플리케이션에 할당하도록 해야 한다.   

Kubernetes 클러스터에서 형성되는 노드는 physical 또는 virtual 일 수 있다.   
앞으로의 예제에서, 가상 시스템을 클러스터의 노드로 가상 박스 환경에 배포하게 될 것이다.   
물리적 시스템이나 가상 시스템 또는 GCP, AWS, Azure 또는 선택한 다른 플랫폼과 같은 클라우드 환경에 배포하도록 선택할 수 있고, 3개의 노드, 1개의 마스터 노드 및 2개의 worker 노드로 구성된 클러스터를 구축할 예정이다.   
우리는 마스터 노드가 kubeapi 서버와 같은 제어 구성 요소를 etcd 서버 등에 호스팅하기 위한 것임을 알고 있다.   
그리고 worker 노드는 워크로드를 호스팅하기 위한 것이다.   
그러나 이는 엄격한 요구 사항이 아니며 마스터 노드도 노드로 간주되고 워크로드를 호스팅할 수 있다.   
마스터 노드는 특히 프로덕션 환경에서 components 제어 전용으로 사용하는 것이 좋다.   
kubeadm과 같은 배포 도구는 마스터 노드에 taint을 추가하여 마스터 노드에서 워크로드를 호스팅하는 것을 방지한다.   
노드에는 64비트 리눅스 운영 체제를 사용해야 한다.   
또 하나 주의할 점은 일반적으로 마스터 노드에 모든 control plane 구성 요소가 있다는 것이다.   
그러나 대규모 클러스터의 경우 마스터 노드에서 자체 클러스터 노드로 etcd 클러스터를 분리하도록 선택할 수 있다.   
<img width="609" alt="스크린샷 2023-01-27 오후 10 49 03" src="https://user-images.githubusercontent.com/83587720/215102310-7661f80c-b98b-42e9-8a1c-3abd927faa30.png">

